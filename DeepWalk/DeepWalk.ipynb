{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:10:25.142580Z",
     "start_time": "2021-08-02T16:10:24.052019Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "#import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:10:53.350572Z",
     "start_time": "2021-08-02T16:10:53.345410Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_graph(input,weighted,directed):\n",
    "    '''\n",
    "    Reads the input network in networkx.\n",
    "    '''\n",
    "    # 权重图\n",
    "    if weighted:\n",
    "        G = nx.read_edgelist(input, nodetype=int, data=(('weight', float),), create_using=nx.DiGraph())\n",
    "    # 无权图\n",
    "    else:\n",
    "        G = nx.read_edgelist(input, nodetype=int, create_using=nx.DiGraph())\n",
    "        for edge in G.edges():\n",
    "            G[edge[0]][edge[1]]['weight'] = 1\n",
    "    # 无向操作\n",
    "    if not directed:\n",
    "        G = G.to_undirected()\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:11:01.391470Z",
     "start_time": "2021-08-02T16:11:01.387584Z"
    }
   },
   "outputs": [],
   "source": [
    "nx_G = read_graph('../Graph/karate.edgelist',False,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:17:49.329355Z",
     "start_time": "2021-08-02T16:17:49.317988Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Graph():\n",
    "    # 出事化设置参数\n",
    "    def __init__(self, nx_G, is_directed):\n",
    "        self.G = nx_G\n",
    "        self.is_directed = is_directed\n",
    "       \n",
    "    \n",
    "    def deep_walk(self, walk_length, start_node):\n",
    "        '''\n",
    "        Simulate a random walk starting from start node.\n",
    "        '''\n",
    "        G = self.G\n",
    "        # 上一步计算出的alias table，完成O(1)的采样\n",
    "        alias_nodes = self.alias_nodes\n",
    "\n",
    "        walk = [start_node]\n",
    "\n",
    "        #  直到生成长度为walk_length的节点序列位为止\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            # 对邻居节点排序，目的是和alias table计算时的顺序对应起来\n",
    "            cur_nbrs = sorted(G.neighbors(cur))\n",
    "            if len(cur_nbrs) > 0:\n",
    "                # 节点序列只有一个节点的情况\n",
    "                walk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "               \n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return walk\n",
    "\n",
    "    def simulate_walks(self, num_walks, walk_length):\n",
    "        '''\n",
    "        Repeatedly simulate random walks from each node.\n",
    "        '''\n",
    "        G = self.G\n",
    "        walks = []\n",
    "        nodes = list(G.nodes())\n",
    "        print ('Walk iteration:')\n",
    "        for walk_iter in range(num_walks):\n",
    "            print (str(walk_iter+1), '/', str(num_walks))\n",
    "            # 打乱节点顺序\n",
    "            random.shuffle(nodes)\n",
    "            for node in nodes:\n",
    "                # node2vec_walk是一次有偏的随机游走\n",
    "                walks.append(self.deep_walk(walk_length=walk_length, start_node=node))\n",
    "\n",
    "        return walks\n",
    "\n",
    "\n",
    "    def preprocess_transition_probs(self):\n",
    "        '''\n",
    "        Preprocessing of transition probabilities for guiding the random walks.\n",
    "        '''\n",
    "        G = self.G\n",
    "        is_directed = self.is_directed\n",
    "\n",
    "        alias_nodes = {}\n",
    "        # 节点概率alias sampling和归一化\n",
    "        for node in G.nodes():\n",
    "            unnormalized_probs = [G[node][nbr]['weight'] for nbr in sorted(G.neighbors(node))]\n",
    "            norm_const = sum(unnormalized_probs)\n",
    "            normalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "            alias_nodes[node] = alias_setup(normalized_probs)\n",
    "            # 信息展示\n",
    "            if node == 2:\n",
    "                print (unnormalized_probs)\n",
    "                print (norm_const)\n",
    "                print (normalized_probs)\n",
    "                print (alias_nodes[node])\n",
    "\n",
    "    \n",
    "        \n",
    "        self.alias_nodes = alias_nodes\n",
    "    \n",
    "        return\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:17:49.829896Z",
     "start_time": "2021-08-02T16:17:49.823458Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def alias_setup(probs):\n",
    "    '''\n",
    "    Compute utility lists for non-uniform sampling from discrete distributions.\n",
    "    Refer to https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
    "    for details\n",
    "    '''\n",
    "    # 总过K个长度\n",
    "    K = len(probs)\n",
    "    # q个0\n",
    "    q = np.zeros(K)\n",
    "    J = np.zeros(K, dtype=np.int)\n",
    "\n",
    "    smaller = []\n",
    "    larger = []\n",
    "    \n",
    "    # 将各个概率分成两组，一组的概率值大于1，另一组的概率值小于1\n",
    "    for kk, prob in enumerate(probs):\n",
    "        q[kk] = K*prob\n",
    "        if q[kk] < 1.0:\n",
    "            smaller.append(kk)\n",
    "        else:\n",
    "            larger.append(kk)\n",
    "    \n",
    "    # 使用贪心算法，将概率值小于1的不断填满\n",
    "    # pseudo code step 3\n",
    "    while len(smaller) > 0 and len(larger) > 0:\n",
    "        small = smaller.pop()\n",
    "        large = larger.pop()\n",
    "\n",
    "        J[small] = large\n",
    "        # 更新概率值\n",
    "        q[large] = q[large] + q[small] - 1.0\n",
    "        if q[large] < 1.0:\n",
    "            smaller.append(large)\n",
    "        else:\n",
    "            larger.append(large)\n",
    "\n",
    "    return J, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:17:50.479195Z",
     "start_time": "2021-08-02T16:17:50.475473Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def alias_draw(J, q):\n",
    "    '''\n",
    "    Draw sample from a non-uniform discrete distribution using alias sampling.\n",
    "    '''\n",
    "    K = len(J)\n",
    "\n",
    "    kk = int(np.floor(np.random.rand()*K))\n",
    "    # 取自己 \n",
    "    if np.random.rand() < q[kk]:\n",
    "        return kk\n",
    "    # 取alias table存的节点\n",
    "    else:\n",
    "        return J[kk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:17:50.905048Z",
     "start_time": "2021-08-02T16:17:50.902809Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "directed = False\n",
    "G = Graph(nx_G, directed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:17:51.198709Z",
     "start_time": "2021-08-02T16:17:51.194951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "9\n",
      "[0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111]\n",
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0]), array([1., 1., 1., 1., 1., 1., 1., 1., 1.]))\n"
     ]
    }
   ],
   "source": [
    "G.preprocess_transition_probs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:17:51.461589Z",
     "start_time": "2021-08-02T16:17:51.430238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "num_walks = 10\n",
    "walk_length = 20\n",
    "# 有偏的随机游走生成节点序列\n",
    "walks = G.simulate_walks(num_walks, walk_length)\n",
    "# 展示一个节点序列的长度\n",
    "print (len(walks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:18:12.025246Z",
     "start_time": "2021-08-02T16:18:12.020875Z"
    }
   },
   "outputs": [],
   "source": [
    "def learn_embeddings(walks,dimensions,window_size,workers,iter):\n",
    "    '''\n",
    "    Learn embeddings by optimizing the Skipgram objective using SGD.\n",
    "    '''\n",
    "    # 将node的类型int转化为string\n",
    "    # walks = [map(str, walk) for walk in walks]\n",
    "    walk_lol = []\n",
    "    for walk in walks:\n",
    "        tmp = []\n",
    "        for node in walk:\n",
    "            tmp.append(str(node))\n",
    "        walk_lol.append(tmp)\n",
    "    # 调用gensim包运行word2vec\n",
    "    model = Word2Vec(walk_lol, size=dimensions, window=window_size, min_count=0, sg=1, workers=workers,\n",
    "                     iter=iter)\n",
    "    # model.save_word2vec_format(args.output)\n",
    "    # 保存embedding信息\n",
    "#     model.wv.save_word2vec_format(args.output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:18:18.839648Z",
     "start_time": "2021-08-02T16:18:18.820255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "model = learn_embeddings(walks,16,3,-1,10)\n",
    "print ('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:18:28.260919Z",
     "start_time": "2021-08-02T16:18:28.255717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1182999536395073\n",
      "-0.049709271639585495\n",
      "0.011760308407247066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import spatial\n",
    "def cos_similarity(v1, v2):\n",
    "    return 1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "# # 相似节点组1\n",
    "print (cos_similarity(model['17'], model['6']))\n",
    "print (cos_similarity(model['7'], model['6']))\n",
    "print (cos_similarity(model['7'], model['5']))\n",
    "\n",
    "\n",
    "# # 相似节点组2\n",
    "# print (cos_similarity(model['34'], model['33']))\n",
    "# print (cos_similarity(model['34'], model['9']))\n",
    "# print (cos_similarity(model['34'], model['31']))\n",
    "\n",
    "# # 不相似节点组\n",
    "# print (cos_similarity(model['17'], model['25']))\n",
    "# print (cos_similarity(model['7'], model['25']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:18:36.399457Z",
     "start_time": "2021-08-02T16:18:35.625565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 1, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 2, 0, 1, 0, 1, 2,\n",
       "       0, 1, 2, 0, 0, 2, 1, 0, 2, 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# k-means聚类\n",
    "from sklearn import  cluster\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "embedding_node=[]\n",
    "for i in range(1,35):\n",
    "    j=str(i)\n",
    "    embedding_node.append(model[j])\n",
    "embedding_node=np.matrix(embedding_node).reshape((34,-1))\n",
    "y_pred = cluster.KMeans(n_clusters=3, random_state=9).fit_predict(embedding_node) # 调用 test_RandomForestClassifier\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
