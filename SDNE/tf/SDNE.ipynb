{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:14:06.274223Z",
     "start_time": "2021-08-29T08:14:02.024707Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class MNN(keras.Model):\n",
    "    def __init__(self, node_size, nhid0, nhid1, droput, alpha):\n",
    "        super(MNN, self).__init__()\n",
    "        self.encode0 = tf.keras.layers.Dense(node_size, nhid0)\n",
    "        self.encode1 = tf.keras.layers.Dense(nhid0, nhid1)\n",
    "        self.decode0 = tf.keras.layers.Dense(nhid1, nhid0)\n",
    "        self.decode1 = tf.keras.layers.Dense(nhid0, node_size)\n",
    "        self.droput = droput\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self, adj_batch, adj_mat, b_mat):\n",
    "        t0 = tf.keras.layers.LeakyReLU(self.encode0(adj_batch))\n",
    "        t0 = tf.keras.layers.LeakyReLU(self.encode1(t0))\n",
    "        embedding = t0\n",
    "        t0 = tf.keras.layers.LeakyReLU(self.decode0(t0))\n",
    "        t0 = tf.keras.layers.LeakyReLU(self.decode1(t0))\n",
    "        embedding_norm = tf.reduce_sum(embedding * embedding, axis=1, keepdims=True)\n",
    "        L_1st = tf.reduce_sum(adj_mat * (embedding_norm -\n",
    "                                     2 * tf.matmul(embedding, tf.transpose(embedding))\n",
    "                                     + tf.transpose(embedding_norm)))\n",
    "        L_2nd = tf.reduce_sum(((adj_batch - t0) * b_mat) * ((adj_batch - t0) * b_mat))\n",
    "        return L_1st, self.alpha * L_2nd, L_1st + self.alpha * L_2nd\n",
    "\n",
    "    def savector(self, adj):\n",
    "        t0 = self.encode0(adj)\n",
    "        t0 = self.encode1(t0)\n",
    "        return t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:14:06.615544Z",
     "start_time": "2021-08-29T08:14:06.276380Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:45:38.308261Z",
     "start_time": "2021-08-29T08:45:38.301321Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def Read_graph(file_name):\n",
    "    # 文本文件中的每一行必须含有相同的数据; delimiter分隔符默认是空格; 类型是numpy array\n",
    "    edge = np.loadtxt(file_name).astype(np.int32)\n",
    "    # 得到图中点的最小和最大编号; .min()返回数组中所有元素最小的\n",
    "    min_node, max_node = edge.min(), edge.max()\n",
    "    # Node表示图上一共有多少个顶点，如果标号是从0开始，那么顶点数 = max_node + 1\n",
    "    if min_node == 0:\n",
    "        Node = max_node + 1\n",
    "    else:\n",
    "        Node = max_node\n",
    "    # 这里面使用networkx将图的信息存入\n",
    "    G = nx.Graph()\n",
    "    # Adj就是图的邻接表矩阵，是一个n*n大小的numpy矩阵，这里n是顶点的个数\n",
    "    Adj = np.zeros([Node, Node], dtype=np.int32)\n",
    "    # 遍历边的文件，将每条边存入networkx的图，以及邻接矩阵Adj所对应的位置(i, j)\n",
    "    for i in range(edge.shape[0]):\n",
    "        G.add_edge(edge[i][0], edge[i][1])\n",
    "        if min_node == 0:\n",
    "            Adj[edge[i][0], edge[i][1]] = 1\n",
    "            Adj[edge[i][1], edge[i][0]] = 1\n",
    "        else:\n",
    "            Adj[edge[i][0] - 1, edge[i][1] - 1] = 1\n",
    "            Adj[edge[i][1] - 1, edge[i][0] - 1] = 1\n",
    "    # 转化成tensor\n",
    "    Adj = np.array(Adj)\n",
    "\n",
    "    return G, Adj, Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:45:38.944940Z",
     "start_time": "2021-08-29T08:45:38.918707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24], shape=(25,), dtype=int32)\n",
      "[[0 1 1 ... 1 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 1 0 1]\n",
      " [0 0 0 ... 1 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 25 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-f81365a16913>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAdj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0madj_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAdj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0madj_mat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0madj_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mb_mat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mones_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0madj_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for array: array is 2-dimensional, but 25 were indexed"
     ]
    }
   ],
   "source": [
    "G, Adj, Node = Read_graph('../../Graph/karate.edgelist')\n",
    "Data = tf.data.Dataset.from_tensor_slices([i for i in range(Node)])\n",
    "Test = Data.batch(25)\n",
    "for index in Test:\n",
    "    print(index)\n",
    "    print(Adj)\n",
    "    adj_batch = Adj[index]\n",
    "    adj_mat = adj_batch[:, index]\n",
    "    b_mat = torch.ones_like(adj_batch)\n",
    "    b_mat[adj_batch != 0] = 5\n",
    "    print(b_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:45:49.383517Z",
     "start_time": "2021-08-29T08:45:49.379232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 1, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adj[1,2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:24:44.697769Z",
     "start_time": "2021-08-29T08:24:44.693740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: (None, 34), types: tf.int32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T16:21:03.642779Z",
     "start_time": "2021-08-28T16:21:03.633695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34, 34), dtype=int32, numpy=\n",
       "array([[0, 1, 1, ..., 1, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}