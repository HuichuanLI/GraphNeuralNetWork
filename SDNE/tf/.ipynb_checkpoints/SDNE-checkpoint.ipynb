{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:29:52.588852Z",
     "start_time": "2021-08-29T09:29:52.577807Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "class MNN(keras.Model):\n",
    "    def __init__(self, node_size, nhid0, nhid1, droput, alpha):\n",
    "        super(MNN, self).__init__()\n",
    "        self.encode0 = tf.keras.layers.Dense(nhid0,kernel_regularizer=regularizers.L1L2(nu1, nu2))\n",
    "        self.encode1 = tf.keras.layers.Dense(nhid1,kernel_regularizer=regularizers.L1L2(nu1, nu2))\n",
    "        self.decode0 = tf.keras.layers.Dense(nhid0,kernel_regularizer=regularizers.L1L2(nu1, nu2))\n",
    "        self.decode1 = tf.keras.layers.Dense(node_size,kernel_regularizer=regularizers.L1L2(nu1, nu2))\n",
    "        self.activation = tf.keras.layers.LeakyReLU()\n",
    "        self.droput = droput\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self, adj_batch, adj_mat, b_mat):\n",
    "        \n",
    "        t0 = self.activation(self.encode0(adj_batch))\n",
    "        t0 = self.activation(self.encode1(t0))\n",
    "        embedding = t0\n",
    "        t0 = self.activation(self.decode0(t0))\n",
    "        t0 = self.activation(self.decode1(t0))\n",
    "        embedding_norm = tf.reduce_sum(embedding * embedding, axis=1, keepdims=True)\n",
    "        L_1st = tf.reduce_sum(tf.cast(adj_mat,dtype=tf.float32) * (embedding_norm -\n",
    "                                     2 * tf.matmul(embedding, tf.transpose(embedding))\n",
    "                                     + tf.transpose(embedding_norm)))\n",
    "        \n",
    "        \n",
    "        L_2nd = tf.reduce_sum((\n",
    "            (tf.cast(adj_batch,dtype=tf.float32) - t0) * tf.cast(b_mat,dtype=tf.float32)) * ((tf.cast(adj_batch,dtype=tf.float32) - t0) * tf.cast(b_mat,dtype=tf.float32)))\n",
    "        return L_1st, self.alpha * L_2nd, L_1st + self.alpha * L_2nd\n",
    "\n",
    "    def savector(self, adj):\n",
    "        t0 = self.encode0(adj)\n",
    "        t0 = self.encode1(t0)\n",
    "        return t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:16:23.624683Z",
     "start_time": "2021-08-29T09:16:23.622387Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:45:38.308261Z",
     "start_time": "2021-08-29T08:45:38.301321Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def Read_graph(file_name):\n",
    "    # 文本文件中的每一行必须含有相同的数据; delimiter分隔符默认是空格; 类型是numpy array\n",
    "    edge = np.loadtxt(file_name).astype(np.int32)\n",
    "    # 得到图中点的最小和最大编号; .min()返回数组中所有元素最小的\n",
    "    min_node, max_node = edge.min(), edge.max()\n",
    "    # Node表示图上一共有多少个顶点，如果标号是从0开始，那么顶点数 = max_node + 1\n",
    "    if min_node == 0:\n",
    "        Node = max_node + 1\n",
    "    else:\n",
    "        Node = max_node\n",
    "    # 这里面使用networkx将图的信息存入\n",
    "    G = nx.Graph()\n",
    "    # Adj就是图的邻接表矩阵，是一个n*n大小的numpy矩阵，这里n是顶点的个数\n",
    "    Adj = np.zeros([Node, Node], dtype=np.int32)\n",
    "    # 遍历边的文件，将每条边存入networkx的图，以及邻接矩阵Adj所对应的位置(i, j)\n",
    "    for i in range(edge.shape[0]):\n",
    "        G.add_edge(edge[i][0], edge[i][1])\n",
    "        if min_node == 0:\n",
    "            Adj[edge[i][0], edge[i][1]] = 1\n",
    "            Adj[edge[i][1], edge[i][0]] = 1\n",
    "        else:\n",
    "            Adj[edge[i][0] - 1, edge[i][1] - 1] = 1\n",
    "            Adj[edge[i][1] - 1, edge[i][0] - 1] = 1\n",
    "    # 转化成tensor\n",
    "    Adj = np.array(Adj)\n",
    "\n",
    "    return G, Adj, Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:51:10.731954Z",
     "start_time": "2021-08-29T08:51:10.711978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[[0 1 1 ... 1 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 1 0 1]\n",
      " [0 0 0 ... 1 1 0]]\n",
      "[[False  True  True  True  True  True  True  True  True False  True  True\n",
      "   True  True False False False  True False  True False  True False False\n",
      "  False False False False False False False  True False False]\n",
      " [ True False  True  True False False False  True False False False False\n",
      "  False  True False False False  True False  True False  True False False\n",
      "  False False False False False False  True False False False]\n",
      " [ True  True False  True False False False  True  True  True False False\n",
      "  False  True False False False False False False False False False False\n",
      "  False False False  True  True False False False  True False]\n",
      " [ True  True  True False False False False  True False False False False\n",
      "   True  True False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True False False False False False  True False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True False False False False False  True False False False  True False\n",
      "  False False False False  True False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True False False False  True  True False False False False False False\n",
      "  False False False False  True False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True  True  True  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True]\n",
      " [ True False False False  True  True False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True  True  True  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [False False False False False  True  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [ True  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [ True  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [ True  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False  True False  True False  True False False  True  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False  True False  True False False False  True False False]]\n",
      "[[1 5 5 5 5 5 5 5 5 1 5 5 5 5 1 1 1 5 1 5 1 5 1 1 1 1 1 1 1 1 1 5 1 1]\n",
      " [5 1 5 5 1 1 1 5 1 1 1 1 1 5 1 1 1 5 1 5 1 5 1 1 1 1 1 1 1 1 5 1 1 1]\n",
      " [5 5 1 5 1 1 1 5 5 5 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 1 1 1 5 1]\n",
      " [5 5 5 1 1 1 1 5 1 1 1 1 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 1 1 1 1 1 5 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 1 1 1 1 1 5 1 1 1 5 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 1 1 1 5 5 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 5 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5]\n",
      " [5 1 1 1 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 5 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [1 1 1 1 1 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 5 1 5 1 1 5 5]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 5 1 1 1 5 1 1]]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "[[0 1 1 ... 1 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 1 0 1]\n",
      " [0 0 0 ... 1 1 0]]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "   True False False False False False False  True False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False  True False False False  True]\n",
      " [False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "   True False False False False False False False False  True]\n",
      " [False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False  True False  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "  False False  True False False False False False  True  True]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True  True]\n",
      " [ True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True  True False False  True False False False  True  True]\n",
      " [False False  True False False False False False  True False False False\n",
      "  False False  True  True False False  True False  True False  True  True\n",
      "  False False False False False  True  True  True False  True]\n",
      " [False False False False False False False False  True  True False False\n",
      "  False  True  True  True False False  True  True  True False  True  True\n",
      "  False False  True  True  True  True  True  True  True False]]\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 1 1 1 1 1 1 5 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 5]\n",
      " [1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 1 1 1 1 1 1 1 1 5]\n",
      " [1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 5]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 5 1 1 1 1 1 5 5]\n",
      " [1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5]\n",
      " [5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 1 1 5 1 1 1 5 5]\n",
      " [1 1 5 1 1 1 1 1 5 1 1 1 1 1 5 5 1 1 5 1 5 1 5 5 1 1 1 1 1 5 5 5 1 5]\n",
      " [1 1 1 1 1 1 1 1 5 5 1 1 1 5 5 5 1 1 5 5 5 1 5 5 1 1 5 5 5 5 5 5 5 1]]\n"
     ]
    }
   ],
   "source": [
    "G, Adj, Node = Read_graph('../../Graph/karate.edgelist')\n",
    "Data = tf.data.Dataset.from_tensor_slices([i for i in range(Node)])\n",
    "Test = Data.batch(25)\n",
    "for index in Test:\n",
    "    print(index.numpy())\n",
    "    index= index.numpy()\n",
    "    print(Adj)\n",
    "    adj_batch = Adj[index]\n",
    "    adj_mat = adj_batch[:, index]\n",
    "    b_mat = np.ones_like(adj_batch)\n",
    "    print(adj_batch != 0)\n",
    "    b_mat[adj_batch != 0] = 5\n",
    "    print(b_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T08:49:39.954056Z",
     "start_time": "2021-08-29T08:49:39.949524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: (None,), types: tf.int32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:21:00.238087Z",
     "start_time": "2021-08-29T09:21:00.234826Z"
    }
   },
   "outputs": [],
   "source": [
    "nhid0 = 1000\n",
    "nhid1 = 128 \n",
    "dropout = 0.5\n",
    "alpha = 1e-2\n",
    "lr = 0.001 \n",
    "step_size = 10 \n",
    "decay_rate = 0.9 \n",
    "beta = 5\n",
    "epochs = 100\n",
    "nu1 = 1e-5\n",
    "nu2 = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:29:56.586120Z",
     "start_time": "2021-08-29T09:29:56.572031Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ./models/model.py中的MNN类，基于pytorch实现的论文中的自编码器\n",
    "model = MNN(Node, nhid0, nhid1, dropout, alpha)\n",
    "# Adam算法优化模型参数\n",
    "opt = keras.optimizers.Adam(0.01)\n",
    "# 设置模型的学习率的超参数\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr, decay_steps=step_size, decay_rate=decay_rate, staircase=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:30:06.099151Z",
     "start_time": "2021-08-29T09:30:03.423539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 1 is:\n",
      "loss_sum is 676.611694\n",
      "loss_L1 is 633.834412\n",
      "loss_L2 is 42.777283\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 2 is:\n",
      "loss_sum is 727.901611\n",
      "loss_L1 is 684.691284\n",
      "loss_L2 is 43.210342\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 3 is:\n",
      "loss_sum is 441.288330\n",
      "loss_L1 is 408.769287\n",
      "loss_L2 is 32.519043\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 4 is:\n",
      "loss_sum is 354.041077\n",
      "loss_L1 is 328.453278\n",
      "loss_L2 is 25.587814\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 5 is:\n",
      "loss_sum is 182.580002\n",
      "loss_L1 is 159.379379\n",
      "loss_L2 is 23.200623\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 6 is:\n",
      "loss_sum is 206.526947\n",
      "loss_L1 is 189.925919\n",
      "loss_L2 is 16.601036\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 7 is:\n",
      "loss_sum is 165.898560\n",
      "loss_L1 is 146.989807\n",
      "loss_L2 is 18.908747\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 8 is:\n",
      "loss_sum is 108.330643\n",
      "loss_L1 is 97.102730\n",
      "loss_L2 is 11.227909\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 9 is:\n",
      "loss_sum is 80.959564\n",
      "loss_L1 is 69.666542\n",
      "loss_L2 is 11.293022\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 10 is:\n",
      "loss_sum is 63.675621\n",
      "loss_L1 is 52.854729\n",
      "loss_L2 is 10.820893\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 11 is:\n",
      "loss_sum is 47.687325\n",
      "loss_L1 is 39.178829\n",
      "loss_L2 is 8.508497\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 12 is:\n",
      "loss_sum is 42.100796\n",
      "loss_L1 is 33.688507\n",
      "loss_L2 is 8.412290\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 13 is:\n",
      "loss_sum is 34.801586\n",
      "loss_L1 is 27.452625\n",
      "loss_L2 is 7.348961\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 14 is:\n",
      "loss_sum is 27.876934\n",
      "loss_L1 is 21.945793\n",
      "loss_L2 is 5.931142\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 15 is:\n",
      "loss_sum is 27.765984\n",
      "loss_L1 is 21.474789\n",
      "loss_L2 is 6.291193\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 16 is:\n",
      "loss_sum is 24.478666\n",
      "loss_L1 is 18.291542\n",
      "loss_L2 is 6.187123\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 17 is:\n",
      "loss_sum is 19.709160\n",
      "loss_L1 is 14.016830\n",
      "loss_L2 is 5.692329\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 18 is:\n",
      "loss_sum is 17.856510\n",
      "loss_L1 is 12.271486\n",
      "loss_L2 is 5.585023\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 19 is:\n",
      "loss_sum is 16.820190\n",
      "loss_L1 is 11.388942\n",
      "loss_L2 is 5.431249\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 20 is:\n",
      "loss_sum is 13.801479\n",
      "loss_L1 is 8.847069\n",
      "loss_L2 is 4.954410\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 21 is:\n",
      "loss_sum is 11.512129\n",
      "loss_L1 is 6.861877\n",
      "loss_L2 is 4.650250\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 22 is:\n",
      "loss_sum is 10.768204\n",
      "loss_L1 is 6.163391\n",
      "loss_L2 is 4.604814\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 23 is:\n",
      "loss_sum is 9.696366\n",
      "loss_L1 is 5.412189\n",
      "loss_L2 is 4.284177\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 24 is:\n",
      "loss_sum is 8.890676\n",
      "loss_L1 is 4.597539\n",
      "loss_L2 is 4.293137\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 25 is:\n",
      "loss_sum is 8.559994\n",
      "loss_L1 is 4.370031\n",
      "loss_L2 is 4.189963\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 26 is:\n",
      "loss_sum is 9.163275\n",
      "loss_L1 is 3.654975\n",
      "loss_L2 is 5.508299\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 27 is:\n",
      "loss_sum is 10.573296\n",
      "loss_L1 is 3.583238\n",
      "loss_L2 is 6.990058\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 28 is:\n",
      "loss_sum is 14.750906\n",
      "loss_L1 is 2.654670\n",
      "loss_L2 is 12.096235\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 29 is:\n",
      "loss_sum is 8.150211\n",
      "loss_L1 is 2.844708\n",
      "loss_L2 is 5.305502\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 30 is:\n",
      "loss_sum is 8.156781\n",
      "loss_L1 is 2.296115\n",
      "loss_L2 is 5.860666\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 31 is:\n",
      "loss_sum is 7.377522\n",
      "loss_L1 is 2.023777\n",
      "loss_L2 is 5.353745\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 32 is:\n",
      "loss_sum is 6.716606\n",
      "loss_L1 is 2.145452\n",
      "loss_L2 is 4.571154\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 33 is:\n",
      "loss_sum is 6.466078\n",
      "loss_L1 is 1.900924\n",
      "loss_L2 is 4.565154\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 34 is:\n",
      "loss_sum is 6.033351\n",
      "loss_L1 is 1.715565\n",
      "loss_L2 is 4.317786\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 35 is:\n",
      "loss_sum is 6.275705\n",
      "loss_L1 is 2.413108\n",
      "loss_L2 is 3.862597\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 36 is:\n",
      "loss_sum is 6.555829\n",
      "loss_L1 is 2.868457\n",
      "loss_L2 is 3.687371\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 37 is:\n",
      "loss_sum is 5.276102\n",
      "loss_L1 is 1.610590\n",
      "loss_L2 is 3.665512\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 38 is:\n",
      "loss_sum is 5.996493\n",
      "loss_L1 is 2.274693\n",
      "loss_L2 is 3.721800\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 39 is:\n",
      "loss_sum is 5.161838\n",
      "loss_L1 is 1.683657\n",
      "loss_L2 is 3.478181\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 40 is:\n",
      "loss_sum is 6.255066\n",
      "loss_L1 is 2.668886\n",
      "loss_L2 is 3.586181\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 41 is:\n",
      "loss_sum is 6.468220\n",
      "loss_L1 is 2.620632\n",
      "loss_L2 is 3.847588\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 42 is:\n",
      "loss_sum is 5.018583\n",
      "loss_L1 is 1.568140\n",
      "loss_L2 is 3.450443\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 43 is:\n",
      "loss_sum is 4.951892\n",
      "loss_L1 is 1.590033\n",
      "loss_L2 is 3.361860\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 44 is:\n",
      "loss_sum is 5.561084\n",
      "loss_L1 is 1.728563\n",
      "loss_L2 is 3.832521\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 45 is:\n",
      "loss_sum is 5.692370\n",
      "loss_L1 is 1.699058\n",
      "loss_L2 is 3.993312\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 46 is:\n",
      "loss_sum is 7.322131\n",
      "loss_L1 is 1.190882\n",
      "loss_L2 is 6.131249\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 47 is:\n",
      "loss_sum is 9.381681\n",
      "loss_L1 is 2.052987\n",
      "loss_L2 is 7.328694\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 48 is:\n",
      "loss_sum is 16.070965\n",
      "loss_L1 is 2.151696\n",
      "loss_L2 is 13.919270\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 49 is:\n",
      "loss_sum is 7.393719\n",
      "loss_L1 is 1.507031\n",
      "loss_L2 is 5.886688\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 50 is:\n",
      "loss_sum is 17.791988\n",
      "loss_L1 is 5.059321\n",
      "loss_L2 is 12.732667\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 51 is:\n",
      "loss_sum is 25.729742\n",
      "loss_L1 is 11.946552\n",
      "loss_L2 is 13.783190\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 52 is:\n",
      "loss_sum is 30.110161\n",
      "loss_L1 is 18.510490\n",
      "loss_L2 is 11.599671\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 53 is:\n",
      "loss_sum is 31.437828\n",
      "loss_L1 is 22.663054\n",
      "loss_L2 is 8.774775\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 54 is:\n",
      "loss_sum is 19.222218\n",
      "loss_L1 is 12.209875\n",
      "loss_L2 is 7.012344\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 55 is:\n",
      "loss_sum is 30.000099\n",
      "loss_L1 is 23.130331\n",
      "loss_L2 is 6.869769\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 56 is:\n",
      "loss_sum is 40.122810\n",
      "loss_L1 is 33.118042\n",
      "loss_L2 is 7.004772\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 57 is:\n",
      "loss_sum is 61.572273\n",
      "loss_L1 is 53.483559\n",
      "loss_L2 is 8.088714\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 58 is:\n",
      "loss_sum is 38.506989\n",
      "loss_L1 is 31.821964\n",
      "loss_L2 is 6.685021\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 59 is:\n",
      "loss_sum is 26.332325\n",
      "loss_L1 is 19.164461\n",
      "loss_L2 is 7.167865\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 60 is:\n",
      "loss_sum is 23.450768\n",
      "loss_L1 is 17.044628\n",
      "loss_L2 is 6.406139\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 61 is:\n",
      "loss_sum is 19.865950\n",
      "loss_L1 is 13.881311\n",
      "loss_L2 is 5.984639\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 62 is:\n",
      "loss_sum is 17.496050\n",
      "loss_L1 is 11.183477\n",
      "loss_L2 is 6.312572\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 63 is:\n",
      "loss_sum is 13.743544\n",
      "loss_L1 is 8.402047\n",
      "loss_L2 is 5.341497\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 64 is:\n",
      "loss_sum is 10.638485\n",
      "loss_L1 is 5.929395\n",
      "loss_L2 is 4.709090\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 65 is:\n",
      "loss_sum is 9.622149\n",
      "loss_L1 is 4.970072\n",
      "loss_L2 is 4.652076\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 66 is:\n",
      "loss_sum is 9.623931\n",
      "loss_L1 is 5.134471\n",
      "loss_L2 is 4.489460\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 67 is:\n",
      "loss_sum is 8.957832\n",
      "loss_L1 is 4.577809\n",
      "loss_L2 is 4.380024\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 68 is:\n",
      "loss_sum is 7.689901\n",
      "loss_L1 is 3.237036\n",
      "loss_L2 is 4.452865\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 69 is:\n",
      "loss_sum is 6.684289\n",
      "loss_L1 is 2.255385\n",
      "loss_L2 is 4.428904\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 70 is:\n",
      "loss_sum is 6.227216\n",
      "loss_L1 is 1.972620\n",
      "loss_L2 is 4.254596\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 71 is:\n",
      "loss_sum is 6.205547\n",
      "loss_L1 is 1.926999\n",
      "loss_L2 is 4.278548\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 72 is:\n",
      "loss_sum is 6.038745\n",
      "loss_L1 is 1.871580\n",
      "loss_L2 is 4.167165\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 73 is:\n",
      "loss_sum is 5.740495\n",
      "loss_L1 is 1.671890\n",
      "loss_L2 is 4.068605\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 74 is:\n",
      "loss_sum is 5.409284\n",
      "loss_L1 is 1.397806\n",
      "loss_L2 is 4.011478\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 75 is:\n",
      "loss_sum is 5.153511\n",
      "loss_L1 is 1.219177\n",
      "loss_L2 is 3.934334\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 76 is:\n",
      "loss_sum is 5.093488\n",
      "loss_L1 is 1.053256\n",
      "loss_L2 is 4.040232\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 77 is:\n",
      "loss_sum is 4.963880\n",
      "loss_L1 is 1.022294\n",
      "loss_L2 is 3.941586\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 78 is:\n",
      "loss_sum is 5.334788\n",
      "loss_L1 is 0.919026\n",
      "loss_L2 is 4.415763\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 79 is:\n",
      "loss_sum is 5.831799\n",
      "loss_L1 is 1.035930\n",
      "loss_L2 is 4.795868\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 80 is:\n",
      "loss_sum is 7.258799\n",
      "loss_L1 is 0.819712\n",
      "loss_L2 is 6.439086\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 81 is:\n",
      "loss_sum is 7.730690\n",
      "loss_L1 is 0.968829\n",
      "loss_L2 is 6.761861\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 82 is:\n",
      "loss_sum is 7.390985\n",
      "loss_L1 is 0.826934\n",
      "loss_L2 is 6.564051\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 83 is:\n",
      "loss_sum is 5.695287\n",
      "loss_L1 is 0.709701\n",
      "loss_L2 is 4.985586\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 84 is:\n",
      "loss_sum is 5.143542\n",
      "loss_L1 is 0.801808\n",
      "loss_L2 is 4.341734\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 85 is:\n",
      "loss_sum is 5.795476\n",
      "loss_L1 is 0.904232\n",
      "loss_L2 is 4.891245\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 86 is:\n",
      "loss_sum is 4.739583\n",
      "loss_L1 is 0.714127\n",
      "loss_L2 is 4.025457\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 87 is:\n",
      "loss_sum is 5.223425\n",
      "loss_L1 is 0.658279\n",
      "loss_L2 is 4.565145\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 88 is:\n",
      "loss_sum is 4.561821\n",
      "loss_L1 is 0.697376\n",
      "loss_L2 is 3.864445\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 89 is:\n",
      "loss_sum is 4.841175\n",
      "loss_L1 is 0.704023\n",
      "loss_L2 is 4.137152\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 90 is:\n",
      "loss_sum is 4.488372\n",
      "loss_L1 is 0.600224\n",
      "loss_L2 is 3.888148\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 91 is:\n",
      "loss_sum is 4.668561\n",
      "loss_L1 is 0.564966\n",
      "loss_L2 is 4.103595\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 92 is:\n",
      "loss_sum is 4.316927\n",
      "loss_L1 is 0.627391\n",
      "loss_L2 is 3.689536\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 93 is:\n",
      "loss_sum is 4.405354\n",
      "loss_L1 is 0.641594\n",
      "loss_L2 is 3.763760\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 94 is:\n",
      "loss_sum is 4.314034\n",
      "loss_L1 is 0.560849\n",
      "loss_L2 is 3.753184\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 95 is:\n",
      "loss_sum is 4.255511\n",
      "loss_L1 is 0.554205\n",
      "loss_L2 is 3.701307\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 96 is:\n",
      "loss_sum is 4.155381\n",
      "loss_L1 is 0.599101\n",
      "loss_L2 is 3.556280\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 97 is:\n",
      "loss_sum is 4.163047\n",
      "loss_L1 is 0.597818\n",
      "loss_L2 is 3.565229\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 98 is:\n",
      "loss_sum is 4.061459\n",
      "loss_L1 is 0.583327\n",
      "loss_L2 is 3.478132\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 99 is:\n",
      "loss_sum is 4.061611\n",
      "loss_L1 is 0.577457\n",
      "loss_L2 is 3.484154\n",
      "loss_reg is 0.000000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[25 26 27 28 29 30 31 32 33]\n",
      "loss for epoch 100 is:\n",
      "loss_sum is 3.946267\n",
      "loss_L1 is 0.592742\n",
      "loss_L2 is 3.353524\n",
      "loss_reg is 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 选用gpu或cpu训练\n",
    "# 共训练epoch次数\n",
    "Data = tf.data.Dataset.from_tensor_slices([i for i in range(Node)]).batch(25)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss_sum, loss_L1, loss_L2, loss_reg = 0, 0, 0, 0\n",
    "    # 每次训练组数：batchsize\n",
    "    for index in Data:\n",
    "        # Adj = N * N\n",
    "        # batch_size = n\n",
    "        # adj_batch = n * N\n",
    "        index= index.numpy()\n",
    "\n",
    "        adj_batch = Adj[index]\n",
    "        print(index)\n",
    "        # adj_mat = n * n\n",
    "        adj_mat = adj_batch[:, index]\n",
    "        \n",
    "        # 将邻接矩阵中的为0项设为1，为1项设为beta\n",
    "        b_mat = np.ones_like(adj_batch)\n",
    "        b_mat[adj_batch != 0] = beta\n",
    "        adj_batch = tf.convert_to_tensor(adj_batch)\n",
    "        b_mat = tf.convert_to_tensor(b_mat)\n",
    "        adj_mat = tf.convert_to_tensor(adj_mat)\n",
    "        \n",
    "        # 在做BP之前将gradients置0因为是累加的\n",
    "        L_1st, L_2nd, L_all = model(adj_batch, adj_mat, b_mat)\n",
    "        L_reg = 0\n",
    "        \n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            L_1st, L_2nd, L_all = model(adj_batch, adj_mat, b_mat)\n",
    "            loss = L_all\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # 将损失值和正则化项加在一起构成最终的损失函数\n",
    "        # 计算梯度\n",
    "      \n",
    "        # 记录相应部分loss值\n",
    "        loss_sum += loss\n",
    "        # 一阶相似度的loss值\n",
    "        loss_L1 += L_1st\n",
    "        # 二阶相似度的loss值\n",
    "        loss_L2 += L_2nd\n",
    "        # 正则化项loss值\n",
    "    # 每次epoch输出训练情况，loss值等\n",
    "    print(\"loss for epoch %d is:\" %epoch)\n",
    "    print(\"loss_sum is %f\" %loss_sum)\n",
    "    print(\"loss_L1 is %f\" %loss_L1)\n",
    "    print(\"loss_L2 is %f\" %loss_L2)\n",
    "    print(\"loss_reg is %f\" %loss_reg)\n",
    "embedding = model.savector(Adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:31:04.110772Z",
     "start_time": "2021-08-29T09:31:04.106201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13989162, -1.5701236 , -2.1391547 , ..., -0.5981258 ,\n",
       "        -0.6402912 , -0.5369024 ],\n",
       "       [-0.02202164, -1.5351268 , -2.3133867 , ..., -0.64747363,\n",
       "        -0.5031823 , -0.45129693],\n",
       "       [-0.02860043, -1.3366505 , -2.3474708 , ..., -0.44417658,\n",
       "        -0.7338315 , -0.35262   ],\n",
       "       ...,\n",
       "       [ 0.04131178, -0.8395436 , -1.9084347 , ..., -0.14251831,\n",
       "        -0.18977213, -0.4544294 ],\n",
       "       [ 0.05114252, -0.9519491 , -1.8633006 , ..., -0.08990844,\n",
       "        -0.04226676, -0.4284957 ],\n",
       "       [ 0.12561488, -0.939856  , -1.9134054 , ..., -0.18669155,\n",
       "        -0.10901473, -0.5097248 ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T09:36:03.803575Z",
     "start_time": "2021-08-29T09:36:03.761139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# k-means聚类\n",
    "from sklearn import  cluster\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "embedding_node=[]\n",
    "for i in range(Node):\n",
    "    t = embedding[i]\n",
    "    embedding_node.append(t)\n",
    "embedding_node=np.matrix(embedding_node).reshape((Node,-1))\n",
    "y_pred = cluster.KMeans(n_clusters=3, random_state=9).fit_predict(embedding_node) # 调用 test_RandomForestClassifier\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
